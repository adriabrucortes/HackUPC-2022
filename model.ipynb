{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-30 18:10:55.892812: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-30 18:10:55.892845: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as tf\n",
    "import tensorflow.keras.layers as ly\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/adriabrucortes/Documents/Programaci√≥/Data - Hack UPC/Data - Hack UPC/post-preprocessing.py\", line 7, in <module>\n",
      "    raw_train = pd.read_csv(\"train.csv\")\n",
      "  File \"/home/adriabrucortes/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\", line 311, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/adriabrucortes/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 586, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/adriabrucortes/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 482, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "  File \"/home/adriabrucortes/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 811, in __init__\n",
      "    self._engine = self._make_engine(self.engine)\n",
      "  File \"/home/adriabrucortes/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\", line 1040, in _make_engine\n",
      "    return mapping[engine](self.f, **self.options)  # type: ignore[call-arg]\n",
      "  File \"/home/adriabrucortes/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 51, in __init__\n",
      "    self._open_handles(src, kwds)\n",
      "  File \"/home/adriabrucortes/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\", line 222, in _open_handles\n",
      "    self.handles = get_handle(\n",
      "  File \"/home/adriabrucortes/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\", line 702, in get_handle\n",
      "    handle = open(\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'train.csv'\n"
     ]
    }
   ],
   "source": [
    "!python post-preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ID = np.load(\"train.npz\")[\"ID\"].astype(np.str)\n",
    "tr_in = np.load(\"train.npz\")[\"inputs\"].astype(np.float)\n",
    "tr_out = np.load(\"train.npz\")[\"targets\"].astype(np.float)\n",
    "\n",
    "val_ID = np.load(\"val.npz\")[\"ID\"].astype(np.str)\n",
    "val_in = np.load(\"val.npz\")[\"inputs\"].astype(np.float)\n",
    "val_out = np.load(\"val.npz\")[\"targets\"].astype(np.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 15\n",
    "output_size = 1\n",
    "\n",
    "topology = [500, 500, 500, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in topology:\n",
    "    model.add(ly.Dense(units = i, activation='relu'))\n",
    "\n",
    "model.add(ly.dense(units = output_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"huber\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METAVARIABLES\n",
    "M_EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "EARLY_STOPPING = tf.callbacks.EarlyStopping (patience = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit (\n",
    "           x = tr_in, \n",
    "           y = tr_out, \n",
    "           validation_data = (val_in, val_out),\n",
    "           epochs = M_EPOCHS,\n",
    "           batch_size = BATCH_SIZE,\n",
    "           callbacks = [EARLY_STOPPING, tensorboard_callback]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"frozen_model.tf\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ede5a25ac400a1c82459112f43899af261185c8c7ccc3ddc9eaeff40f003ca8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
